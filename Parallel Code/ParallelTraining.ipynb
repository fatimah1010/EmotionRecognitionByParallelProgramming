{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23894 images belonging to 5 classes.\n",
      "Found 5989 images belonging to 5 classes.\n",
      "Epoch 1/70\n",
      "374/374 [==============================] - 138s 364ms/step - loss: 1.5583 - accuracy: 0.3074 - val_loss: 1.4736 - val_accuracy: 0.3987\n",
      "Epoch 2/70\n",
      "374/374 [==============================] - 166s 445ms/step - loss: 1.3656 - accuracy: 0.4346 - val_loss: 1.2662 - val_accuracy: 0.4871\n",
      "Epoch 3/70\n",
      "374/374 [==============================] - 127s 341ms/step - loss: 1.2497 - accuracy: 0.4945 - val_loss: 1.1859 - val_accuracy: 0.5216\n",
      "Epoch 4/70\n",
      "374/374 [==============================] - 135s 361ms/step - loss: 1.1818 - accuracy: 0.5239 - val_loss: 1.1219 - val_accuracy: 0.5485\n",
      "Epoch 5/70\n",
      "374/374 [==============================] - 128s 343ms/step - loss: 1.1214 - accuracy: 0.5539 - val_loss: 1.0708 - val_accuracy: 0.5732\n",
      "Epoch 6/70\n",
      "374/374 [==============================] - 129s 344ms/step - loss: 1.0682 - accuracy: 0.5765 - val_loss: 1.0404 - val_accuracy: 0.5829\n",
      "Epoch 7/70\n",
      "374/374 [==============================] - 129s 344ms/step - loss: 1.0297 - accuracy: 0.5944 - val_loss: 0.9999 - val_accuracy: 0.6091\n",
      "Epoch 8/70\n",
      "374/374 [==============================] - 131s 350ms/step - loss: 0.9900 - accuracy: 0.6095 - val_loss: 0.9870 - val_accuracy: 0.6038\n",
      "Epoch 9/70\n",
      "374/374 [==============================] - 135s 361ms/step - loss: 0.9615 - accuracy: 0.6262 - val_loss: 0.9507 - val_accuracy: 0.6246\n",
      "Epoch 10/70\n",
      "374/374 [==============================] - 132s 353ms/step - loss: 0.9296 - accuracy: 0.6369 - val_loss: 0.9377 - val_accuracy: 0.6266\n",
      "Epoch 11/70\n",
      "374/374 [==============================] - 139s 373ms/step - loss: 0.9032 - accuracy: 0.6483 - val_loss: 0.9180 - val_accuracy: 0.6383\n",
      "Epoch 12/70\n",
      "374/374 [==============================] - 149s 397ms/step - loss: 0.8804 - accuracy: 0.6592 - val_loss: 0.8955 - val_accuracy: 0.6505\n",
      "Epoch 13/70\n",
      "374/374 [==============================] - 145s 388ms/step - loss: 0.8575 - accuracy: 0.6715 - val_loss: 0.8869 - val_accuracy: 0.6502\n",
      "Epoch 14/70\n",
      "374/374 [==============================] - 137s 365ms/step - loss: 0.8386 - accuracy: 0.6795 - val_loss: 0.8864 - val_accuracy: 0.6540\n",
      "Epoch 15/70\n",
      "374/374 [==============================] - 125s 334ms/step - loss: 0.8198 - accuracy: 0.6819 - val_loss: 0.8691 - val_accuracy: 0.6612\n",
      "Epoch 16/70\n",
      "374/374 [==============================] - 126s 337ms/step - loss: 0.7998 - accuracy: 0.6955 - val_loss: 0.8728 - val_accuracy: 0.6600\n",
      "Epoch 17/70\n",
      "374/374 [==============================] - 132s 352ms/step - loss: 0.7815 - accuracy: 0.7015 - val_loss: 0.8571 - val_accuracy: 0.6677\n",
      "Epoch 18/70\n",
      "374/374 [==============================] - 126s 337ms/step - loss: 0.7614 - accuracy: 0.7101 - val_loss: 0.8483 - val_accuracy: 0.6694\n",
      "Epoch 19/70\n",
      "374/374 [==============================] - 132s 353ms/step - loss: 0.7445 - accuracy: 0.7155 - val_loss: 0.8375 - val_accuracy: 0.6726\n",
      "Epoch 20/70\n",
      "374/374 [==============================] - 127s 338ms/step - loss: 0.7317 - accuracy: 0.7220 - val_loss: 0.8292 - val_accuracy: 0.6807\n",
      "Epoch 21/70\n",
      "374/374 [==============================] - 148s 396ms/step - loss: 0.7136 - accuracy: 0.7290 - val_loss: 0.8298 - val_accuracy: 0.6806\n",
      "Epoch 22/70\n",
      "374/374 [==============================] - 151s 404ms/step - loss: 0.6915 - accuracy: 0.7358 - val_loss: 0.8237 - val_accuracy: 0.6801\n",
      "Epoch 23/70\n",
      "374/374 [==============================] - 135s 362ms/step - loss: 0.6768 - accuracy: 0.7453 - val_loss: 0.8248 - val_accuracy: 0.6784\n",
      "Epoch 24/70\n",
      "374/374 [==============================] - 154s 412ms/step - loss: 0.6541 - accuracy: 0.7570 - val_loss: 0.8205 - val_accuracy: 0.6854\n",
      "Epoch 25/70\n",
      "374/374 [==============================] - 146s 390ms/step - loss: 0.6438 - accuracy: 0.7584 - val_loss: 0.8280 - val_accuracy: 0.6779\n",
      "Epoch 26/70\n",
      "374/374 [==============================] - 124s 331ms/step - loss: 0.6265 - accuracy: 0.7619 - val_loss: 0.8199 - val_accuracy: 0.6883\n",
      "Epoch 27/70\n",
      "374/374 [==============================] - 146s 389ms/step - loss: 0.6065 - accuracy: 0.7700 - val_loss: 0.8255 - val_accuracy: 0.6859\n",
      "Epoch 28/70\n",
      "374/374 [==============================] - 146s 389ms/step - loss: 0.5868 - accuracy: 0.7797 - val_loss: 0.8352 - val_accuracy: 0.6876\n",
      "Epoch 29/70\n",
      "374/374 [==============================] - 147s 393ms/step - loss: 0.5729 - accuracy: 0.7811 - val_loss: 0.8219 - val_accuracy: 0.6881\n",
      "Epoch 30/70\n",
      "374/374 [==============================] - 147s 392ms/step - loss: 0.5515 - accuracy: 0.7922 - val_loss: 0.8244 - val_accuracy: 0.6878\n",
      "Epoch 31/70\n",
      "374/374 [==============================] - 147s 394ms/step - loss: 0.5444 - accuracy: 0.7969 - val_loss: 0.8267 - val_accuracy: 0.6921\n",
      "Epoch 32/70\n",
      "374/374 [==============================] - 147s 392ms/step - loss: 0.5190 - accuracy: 0.8072 - val_loss: 0.8278 - val_accuracy: 0.6908\n",
      "Epoch 33/70\n",
      "374/374 [==============================] - 148s 396ms/step - loss: 0.5040 - accuracy: 0.8108 - val_loss: 0.8510 - val_accuracy: 0.6863\n",
      "Epoch 34/70\n",
      "374/374 [==============================] - 145s 389ms/step - loss: 0.4874 - accuracy: 0.8166 - val_loss: 0.8337 - val_accuracy: 0.6906\n",
      "Epoch 35/70\n",
      "374/374 [==============================] - 146s 391ms/step - loss: 0.4736 - accuracy: 0.8233 - val_loss: 0.8328 - val_accuracy: 0.6974\n",
      "Epoch 36/70\n",
      "374/374 [==============================] - 131s 349ms/step - loss: 0.4542 - accuracy: 0.8317 - val_loss: 0.8406 - val_accuracy: 0.6926\n",
      "Epoch 37/70\n",
      "374/374 [==============================] - 148s 397ms/step - loss: 0.4470 - accuracy: 0.8345 - val_loss: 0.8433 - val_accuracy: 0.6958\n",
      "Epoch 38/70\n",
      "374/374 [==============================] - 135s 360ms/step - loss: 0.4277 - accuracy: 0.8420 - val_loss: 0.8588 - val_accuracy: 0.6959\n",
      "Epoch 39/70\n",
      "374/374 [==============================] - 148s 396ms/step - loss: 0.4042 - accuracy: 0.8493 - val_loss: 0.8867 - val_accuracy: 0.6934\n",
      "Epoch 40/70\n",
      "374/374 [==============================] - 145s 388ms/step - loss: 0.3933 - accuracy: 0.8543 - val_loss: 0.8619 - val_accuracy: 0.6959\n",
      "Epoch 41/70\n",
      "374/374 [==============================] - 132s 354ms/step - loss: 0.3860 - accuracy: 0.8575 - val_loss: 0.8865 - val_accuracy: 0.6999\n",
      "Epoch 42/70\n",
      "374/374 [==============================] - 147s 392ms/step - loss: 0.3726 - accuracy: 0.8631 - val_loss: 0.8795 - val_accuracy: 0.6978\n",
      "Epoch 43/70\n",
      "374/374 [==============================] - 144s 385ms/step - loss: 0.3538 - accuracy: 0.8719 - val_loss: 0.8873 - val_accuracy: 0.7003\n",
      "Epoch 44/70\n",
      "374/374 [==============================] - 136s 365ms/step - loss: 0.3400 - accuracy: 0.8741 - val_loss: 0.8928 - val_accuracy: 0.7016\n",
      "Epoch 45/70\n",
      "374/374 [==============================] - 145s 389ms/step - loss: 0.3235 - accuracy: 0.8839 - val_loss: 0.9164 - val_accuracy: 0.6991\n",
      "Epoch 46/70\n",
      "374/374 [==============================] - 144s 386ms/step - loss: 0.3219 - accuracy: 0.8823 - val_loss: 0.9164 - val_accuracy: 0.6984\n",
      "Epoch 47/70\n",
      "374/374 [==============================] - 144s 384ms/step - loss: 0.3040 - accuracy: 0.8892 - val_loss: 0.9160 - val_accuracy: 0.6991\n",
      "Epoch 48/70\n",
      "374/374 [==============================] - 135s 361ms/step - loss: 0.2929 - accuracy: 0.8919 - val_loss: 0.9259 - val_accuracy: 0.7016\n",
      "Epoch 49/70\n",
      "374/374 [==============================] - 113s 301ms/step - loss: 0.2888 - accuracy: 0.8952 - val_loss: 0.9211 - val_accuracy: 0.7033\n",
      "Epoch 50/70\n",
      "374/374 [==============================] - 127s 341ms/step - loss: 0.2700 - accuracy: 0.9030 - val_loss: 0.9816 - val_accuracy: 0.6983\n",
      "Epoch 51/70\n",
      "374/374 [==============================] - 114s 306ms/step - loss: 0.2659 - accuracy: 0.9041 - val_loss: 0.9557 - val_accuracy: 0.6979\n",
      "Epoch 52/70\n",
      "374/374 [==============================] - 123s 329ms/step - loss: 0.2571 - accuracy: 0.9067 - val_loss: 0.9615 - val_accuracy: 0.6973\n",
      "Epoch 53/70\n",
      "374/374 [==============================] - 120s 322ms/step - loss: 0.2478 - accuracy: 0.9106 - val_loss: 0.9586 - val_accuracy: 0.7006\n",
      "Epoch 54/70\n",
      "374/374 [==============================] - 117s 314ms/step - loss: 0.2359 - accuracy: 0.9140 - val_loss: 0.9574 - val_accuracy: 0.7020\n",
      "Epoch 55/70\n",
      "374/374 [==============================] - 124s 332ms/step - loss: 0.2303 - accuracy: 0.9164 - val_loss: 0.9724 - val_accuracy: 0.6973\n",
      "Epoch 56/70\n",
      "374/374 [==============================] - 114s 306ms/step - loss: 0.2229 - accuracy: 0.9183 - val_loss: 1.0032 - val_accuracy: 0.6961\n",
      "Epoch 57/70\n",
      "374/374 [==============================] - 128s 343ms/step - loss: 0.2123 - accuracy: 0.9246 - val_loss: 1.0210 - val_accuracy: 0.6994\n",
      "Epoch 58/70\n",
      "374/374 [==============================] - 112s 300ms/step - loss: 0.2151 - accuracy: 0.9214 - val_loss: 0.9970 - val_accuracy: 0.6964\n",
      "Epoch 59/70\n",
      "374/374 [==============================] - 128s 342ms/step - loss: 0.1994 - accuracy: 0.9304 - val_loss: 1.0320 - val_accuracy: 0.6991\n",
      "Epoch 60/70\n",
      "374/374 [==============================] - 112s 301ms/step - loss: 0.1941 - accuracy: 0.9323 - val_loss: 1.0370 - val_accuracy: 0.7035\n",
      "Epoch 61/70\n",
      "374/374 [==============================] - 122s 325ms/step - loss: 0.1907 - accuracy: 0.9332 - val_loss: 1.0083 - val_accuracy: 0.7013\n",
      "Epoch 62/70\n",
      "374/374 [==============================] - 117s 314ms/step - loss: 0.1837 - accuracy: 0.9355 - val_loss: 1.0777 - val_accuracy: 0.6961\n",
      "Epoch 63/70\n",
      "374/374 [==============================] - 114s 306ms/step - loss: 0.1719 - accuracy: 0.9389 - val_loss: 1.0907 - val_accuracy: 0.6999\n",
      "Epoch 64/70\n",
      "374/374 [==============================] - 123s 328ms/step - loss: 0.1715 - accuracy: 0.9386 - val_loss: 1.0557 - val_accuracy: 0.6931\n",
      "Epoch 65/70\n",
      "374/374 [==============================] - 113s 301ms/step - loss: 0.1706 - accuracy: 0.9386 - val_loss: 1.0640 - val_accuracy: 0.6999\n",
      "Epoch 66/70\n",
      "374/374 [==============================] - 126s 337ms/step - loss: 0.1631 - accuracy: 0.9427 - val_loss: 1.0614 - val_accuracy: 0.6933\n",
      "Epoch 67/70\n",
      "374/374 [==============================] - 113s 302ms/step - loss: 0.1580 - accuracy: 0.9437 - val_loss: 1.1052 - val_accuracy: 0.7001\n",
      "Epoch 68/70\n",
      "374/374 [==============================] - 124s 333ms/step - loss: 0.1557 - accuracy: 0.9443 - val_loss: 1.0922 - val_accuracy: 0.6969\n",
      "Epoch 69/70\n",
      "374/374 [==============================] - 115s 307ms/step - loss: 0.1538 - accuracy: 0.9448 - val_loss: 1.1119 - val_accuracy: 0.6963\n",
      "Epoch 70/70\n",
      "374/374 [==============================] - 115s 309ms/step - loss: 0.1459 - accuracy: 0.9491 - val_loss: 1.1257 - val_accuracy: 0.6963\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import zipfile\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard  \n",
    "\n",
    "# Configure parallelism parameters\n",
    "tf.config.threading.set_intra_op_parallelism_threads(8) \n",
    "\n",
    "# Adjust based on your CPU\n",
    "tf.config.threading.set_inter_op_parallelism_threads(8)  # Adjust based on your CPU\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip files for training and testing data.\n",
    "\n",
    "with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('train_dataset')\n",
    "\n",
    "with zipfile.ZipFile('test.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('test_dataset')   \n",
    "    \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)   \n",
    "\n",
    "# Create train generator\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'train_dataset/train',  # Use the extracted directory\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")       \n",
    "\n",
    "# Create test generator\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    'test_dataset/test',  # Use the extracted directory\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical'\n",
    ")                            \n",
    "\n",
    "# Custom preprocessing function for sharpening using TensorFlow\n",
    "def sharpen_image(image, label):\n",
    "    # Apply Gaussian blur\n",
    "    blurred = tf.image.adjust_contrast(image, contrast_factor=3)\n",
    "    # Perform edge enhancement\n",
    "    sharp_image = tf.clip_by_value(image * 2 - blurred, 0.0, 1.0)\n",
    "    return sharp_image, label     \n",
    "\n",
    "# Function to read and preprocess an image\n",
    "def load_and_preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=1)  # Decode grayscale\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    # Apply sharpening\n",
    "    image, label = sharpen_image(image, label)\n",
    "    \n",
    "    return image, label     \n",
    "\n",
    " # Parameters\n",
    "train_dir = \"train_dataset/train\"\n",
    "validation_dir = \"test_dataset/test\"\n",
    "batch_size = 32          \n",
    "\n",
    "\n",
    "\n",
    "# Function to build dataset with one-hot encoding for labels\n",
    "def build_dataset(directory, batch_size):\n",
    "  # Create a dataset of file paths and labels\n",
    "    file_paths = []\n",
    "    labels = []\n",
    "    label_map = {}\n",
    "    for class_idx, class_name in enumerate(sorted(os.listdir(directory))):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            class_files = [os.path.join(class_dir, fname) for fname in os.listdir(class_dir)]\n",
    "            file_paths.extend(class_files)\n",
    "            labels.extend([class_idx] * len(class_files))\n",
    "            label_map[class_idx] = class_name\n",
    "\n",
    "    file_paths = tf.constant(file_paths)\n",
    "    labels = tf.constant(labels)\n",
    "\n",
    "    # One-hot encode the labels\n",
    "    labels = tf.one_hot(labels, depth=5)  # Adjust 'depth' to match the number of classes\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset, label_map   \n",
    "\n",
    "# Model Creation\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')  \n",
    "])      \n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")      \n",
    "# Create a TensorBoard callback for logging\n",
    "logdir = 'logs'\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)                                                                                                                                                              # Train the model\n",
    "emotion_model_info = model.fit(\n",
    "    train_generator,\n",
    "    epochs=70,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
